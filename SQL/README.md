# Очистка и анализ данных о массовых увольнениях

### Контекст
Этот проект - учебный. Я использую открытый датасет для эмуляции проблемы. Некачественные, разрозненные данные о массовых увольнениях я превращаю в инструмент для анализа, прогнозирования и стратегических решений

### Проблема
В ходе массовых увольнений в датасете образовались дубликаты, пропуски и ошибки. Это мешает анализу и мешает увидеть реальные тренды. 

### Цель
Разобраться в причинах ошибок, обработать дубликаты и пропуски, подготовить датасет к генерации модели  

### Актуальность
Рынок труда — один из главных индикаторов экономической стабильности, и качественная информация о массовых увольнениях нужна как никогда. Этот проект помогает выявлять тренды, прогнозировать последствия и принимать стратегические решения.

## Описание Проекта

Проект состоит из нескольких ключевых этапов:

1. **Очистка данных**:
   - Удаление строк с некорректными датами.
   - Обработка пропущенных или некорректных значений.
   - Исправление несоответствий (например, стандартизация названий компаний, исправление ошибок в написании).

2. **Преобразование данных**:
   - Изменение типов данных на соответствующие (например, преобразование строк в даты или целые числа).
   - Заполнение пропущенных данных на основе других столбцов или стандартов отрасли.

3. **Удаление дубликатов**:
   - Идентификация и удаление дублирующихся строк для обеспечения согласованности данных.

4. **Исследовательский анализ данных (EDA)**:
   - Генерация статистических сводок и визуализаций данных.
   - Агрегация данных для понимания трендов по увольнениям в различных компаниях, отраслях и странах.
   - Расчет накопленных увольнений по месяцам и годам, а также определение топ-5 компаний с наибольшим числом увольнений.

## Файлы в этом репозитории

- `layoffs_cleaning.sql`: SQL-скрипт, включающий все шаги очистки и преобразования данных.
- `README.md`: Документация для проекта, включающая обзор, этапы и инструкции.
- `World Layoffs.csv`: CSV-файл с исходными данными
